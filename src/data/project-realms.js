// AUTO-GENERATED by scripts/build-projects.js — do not edit manually.

export const projectRealmOrder = [
  "bastion-artifact",
  "enemy-ai",
  "asl-translator",
  "finance-wizard"
];

export const projectRealms = {
  "bastion-artifact": {
      "id": "bastion-artifact",
      "path": "project-bastion-artifact.html",
      "title": "Bastion of the Artifact",
      "subtitle": "A tower defense third person video game developed by me and 10 other classmates. The game features enemies, advanced movement like sliding, weapon systems, extensive tower upgrading, and advanced building system",
      "projectTag": "Project",
      "theme": "ledger",
      "modelPath": "",
      "modelScale": 1,
      "accent": "#c9a24b",
      "secondary": "#35463f",
      "impact": "",
      "stack": [
          "Unreal Engine",
          "C++",
          "Agile",
          "Gameplay Systems",
          "Enemy AI"
      ],
      "metrics": [
          {
              "label": "Team",
              "value": "10 Developers"
          },
          {
              "label": "Method",
              "value": "Agile SDLC"
          },
          {
              "label": "Result",
              "value": "Placed 1st"
          }
      ],
      "chapters": [
          "We decided to organize the 10 people into two groups of 5. The two groups would have different roles. One group would be…",
          "Coordinated cross-discipline handoffs between gameplay engineers and content creators. Clear interface contracts and sha…",
          "Delivered cohesive core loops with scalable architecture for future expansion. Combat, AI, inventory, and wave progressi…"
      ],
      "bodies": [
          {
              "title": "Sprint Planning",
              "content": "We decided to organize the 10 people into two groups of 5. The two groups would have different roles. One group would be in charge of models and animations, while the other team would be in charge of the actual coding mechanics and gameplay development. I was put on the development team as I had previous expereince working with and making video games. We initially had a big group meeting where we deiscussed multiple ideas based on the main theme of steampunk or medieval. Our group decided to go more with medieval and magic theme and we continued to discuss the exact details of the game. We soon came to the conclusion that we would make a tower defense game where the player could run around in third person and collect resources to build towers and upgrade them. Soon after, me and another teammate wuickly drafted a storyline for the game and basic thematic resources that we would base models, animations, and enemies after. We then got into more detailed explanations on the game mechanics, characters, enemies, and more gameplay mechanics that we would have. We put all of this informaiton and discussing into a one pager, ten pager, and a 50 pager. The 50 pager can be viewed here: [50-Page Design Document](https://docs.google.com/document/d/1hdWGzpMxa3WuxKq6qWogsNFJ3ueTIUBKpYNrbWRBzV8/edit?usp=sharing). Soon after, we directly got to work.",
              "assets": [
                  "S1.mp4",
                  "P1.png"
              ],
              "layout": "bottom",
              "autoplay": false
          },
          {
              "title": "Cross-Discipline Coordination",
              "content": "Coordinated cross-discipline handoffs between gameplay engineers and content creators. Clear interface contracts and shared documentation kept the 10-person team aligned.",
              "assets": [],
              "layout": "bottom",
              "autoplay": false
          },
          {
              "title": "Systems Integration",
              "content": "Delivered cohesive core loops with scalable architecture for future expansion. Combat, AI, inventory, and wave progression interlock through event-driven communication.",
              "assets": [],
              "layout": "bottom",
              "autoplay": false
          }
      ],
      "thumbnail": "P1.png",
      "assets": {
          "images": [
              "P1.png",
              "P10.png",
              "P11.png",
              "P2.png",
              "P3.png",
              "P4.png",
              "P5.png",
              "P6.png",
              "P7.png",
              "P8.png",
              "P9.png"
          ],
          "videos": [
              "S1.mp4",
              "S2.mp4"
          ],
          "documents": [],
          "links": [
              "Final Presentation: https://docs.google.com/presentation/d/1MVdTFXHo2GmDAlAAh7JaIH0Dfsv5vooUbH1A2ZVxZos/edit?usp=sharing"
          ]
      }
  },
  "enemy-ai": {
      "id": "enemy-ai",
      "path": "project-enemy-ai.html",
      "title": "Enemy AI Behavioral System",
      "subtitle": "A gameplay intelligence stack for Unreal Engine that combines sensory logic, behavior trees, and adaptive reaction loops.",
      "projectTag": "Project",
      "theme": "forge",
      "modelPath": "",
      "modelScale": 1,
      "accent": "#8f6a33",
      "secondary": "#35463f",
      "impact": "",
      "stack": [
          "UE5",
          "C++",
          "Blueprints",
          "Behavior Trees",
          "AI Agents"
      ],
      "metrics": [
          {
              "label": "Engine",
              "value": "UE5"
          },
          {
              "label": "Core",
              "value": "Behavior Trees"
          },
          {
              "label": "Outcome",
              "value": "Adaptive Combat"
          }
      ],
      "chapters": [
          "Modeled sensory channels for line-of-sight, aggression triggers, and retreat logic. Enemies perceive the environment thr…",
          "Implemented behavior tree branches to make enemy intent more legible to players. Each decision node evaluates context — …",
          "Tested tuning profiles for pacing, pressure curves, and difficulty fairness. Iterative playtesting sessions refined the …"
      ],
      "bodies": [
          {
              "title": "Sensory Architecture",
              "content": "Modeled sensory channels for line-of-sight, aggression triggers, and retreat logic. Enemies perceive the environment through layered awareness systems that respond to sound, visibility, and threat proximity.",
              "assets": [],
              "layout": "bottom",
              "autoplay": false
          },
          {
              "title": "Behavior Tree Design",
              "content": "Implemented behavior tree branches to make enemy intent more legible to players. Each decision node evaluates context — health, ammo, player distance — creating emergent tactical choices.",
              "assets": [],
              "layout": "bottom",
              "autoplay": false
          },
          {
              "title": "Tuning & Balancing",
              "content": "Tested tuning profiles for pacing, pressure curves, and difficulty fairness. Iterative playtesting sessions refined the balance between challenge and frustration.",
              "assets": [],
              "layout": "bottom",
              "autoplay": false
          }
      ],
      "thumbnail": "P1.png",
      "assets": {
          "images": [
              "P1.png",
              "P2.png"
          ],
          "videos": [
              "V1.mp4",
              "V2.mp4",
              "V3.mp4",
              "V5.mp4",
              "V6.mp4"
          ],
          "documents": [],
          "links": [
              "Final Presentation: https://www.canva.com/design/DAGW284YVOo/m2Q0znQQiqcKEfzBOn6EiA/view?utm_content=DAGW284YVOo&utm_campaign=designshare&utm_medium=link2&utm_source=uniquelinks&utlId=h63607d6d57"
          ]
      }
  },
  "asl-translator": {
      "id": "asl-translator",
      "path": "project-asl-translator.html",
      "title": "ASL Gesture Translator",
      "subtitle": "A computer vision project that detects your hand movements and signs for sign language.",
      "projectTag": "Project",
      "theme": "signal",
      "modelPath": "",
      "modelScale": 1,
      "accent": "#c9a24b",
      "secondary": "#8f6a33",
      "impact": "",
      "stack": [
          "Python",
          "OpenCV",
          "MediaPipe",
          "MLP",
          "Data Pipeline"
      ],
      "metrics": [
          {
              "label": "Purpose",
              "value": "I mainly built this prokect to learn Computer Vision, AI, and MediaPipe"
          },
          {
              "label": "Accuracy",
              "value": "97%"
          },
          {
              "label": "Data",
              "value": "All data that was used to train the model was made by me and my team"
          }
      ],
      "chapters": [
          "Built a robust data collection and cleaning pipeline from live camera landmarks. MediaPipe extracts 21 hand keypoints pe…",
          "Trained and evaluated MLP variants for recognition confidence and latency tradeoffs. The final architecture balances rea…",
          "Packaged inference outputs into a practical interaction loop for communication support. The system provides visual feedb…"
      ],
      "bodies": [
          {
              "title": "Planning",
              "content": "Built a robust data collection and cleaning pipeline from live camera landmarks. MediaPipe extracts 21 hand keypoints per frame, feeding into a normalization layer that handles varying hand sizes and positions.",
              "assets": [
                  "keypoint.csv"
              ],
              "layout": "left",
              "autoplay": false
          },
          {
              "title": "Model Training",
              "content": "Trained and evaluated MLP variants for recognition confidence and latency tradeoffs. The final architecture balances real-time inference speed with high accuracy across 26 ASL alphabet signs.",
              "assets": [],
              "layout": "bottom",
              "autoplay": false
          },
          {
              "title": "Interaction Design",
              "content": "Packaged inference outputs into a practical interaction loop for communication support. The system provides visual feedback, confidence indicators, and word-building capabilities.",
              "assets": [],
              "layout": "bottom",
              "autoplay": false
          }
      ],
      "thumbnail": "",
      "assets": {
          "images": [],
          "videos": [],
          "documents": [
              "keypoint.csv"
          ],
          "links": []
      }
  },
  "finance-wizard": {
      "id": "finance-wizard",
      "path": "project-finance-wizard.html",
      "title": "Finance Wizard Mobile Port",
      "subtitle": "A native iOS migration focused on making financial literacy feel accessible, visual, and actionable for K-12 learners.",
      "projectTag": "Project",
      "theme": "citadel",
      "modelPath": "",
      "modelScale": 1,
      "accent": "#8f6a33",
      "secondary": "#35463f",
      "impact": "",
      "stack": [
          "Swift",
          "SwiftUI",
          "Firebase",
          "Git",
          "Xcode",
          "and much more"
      ],
      "metrics": [
          {
              "label": "Audience",
              "value": "K-12 Learners"
          },
          {
              "label": "Platform",
              "value": "iOS Native"
          },
          {
              "label": "Focus",
              "value": "Accessibility"
          }
      ],
      "chapters": [
          "Reframed financial education as short visual modules with reduced cognitive load. The app breaks down complex concepts l…",
          "Built reusable SwiftUI components for onboarding, progress, and scenario cards. Each component was designed to be compos…",
          "Connected account flows and product iteration loops through Firebase-backed state. Real-time sync ensures progress is ne…"
      ],
      "bodies": [
          {
              "title": "Visual Learning Modules",
              "content": "Reframed financial education as short visual modules with reduced cognitive load. The app breaks down complex concepts like budgeting, saving, and investing into bite-sized interactive lessons that keep young learners engaged.",
              "assets": [],
              "layout": "bottom",
              "autoplay": false
          },
          {
              "title": "Component Architecture",
              "content": "Built reusable SwiftUI components for onboarding, progress, and scenario cards. Each component was designed to be composable and theme-aware, ensuring a consistent experience across different lesson types.",
              "assets": [],
              "layout": "bottom",
              "autoplay": false
          },
          {
              "title": "Backend Integration",
              "content": "Connected account flows and product iteration loops through Firebase-backed state. Real-time sync ensures progress is never lost, and analytics feed back into content decisions.",
              "assets": [],
              "layout": "bottom",
              "autoplay": false
          }
      ],
      "thumbnail": "",
      "assets": {
          "images": [],
          "videos": [],
          "documents": [],
          "links": []
      }
  }
};

export function getProjectRealm(projectId) {
  return projectRealms[projectId] ?? projectRealms[projectRealmOrder[0]];
}

export function getProjectNeighbors(projectId) {
  const index = projectRealmOrder.indexOf(projectId);
  if (index < 0) {
    return {
      previous: projectRealms[projectRealmOrder[projectRealmOrder.length - 1]],
      next: projectRealms[projectRealmOrder[0]]
    };
  }

  const previous = projectRealms[projectRealmOrder[(index - 1 + projectRealmOrder.length) % projectRealmOrder.length]];
  const next = projectRealms[projectRealmOrder[(index + 1) % projectRealmOrder.length]];
  return { previous, next };
}
